{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Generator,Callable,Optional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "from rl.markov_process import MarkovRewardProcess,FiniteMarkovProcess,MarkovProcess\n",
    "from rl.markov_process import FiniteMarkovRewardProcess\n",
    "from rl.markov_process import Transition,TransitionStep,ReturnStep\n",
    "from rl.markov_process import RewardTransition\n",
    "from rl.distribution import Constant,Categorical,SampledDistribution,Distribution\n",
    "from rl.gen_utils.common_funcs import get_logistic_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: V1: [11.2  4.3  0. ] Q0_s1 [10.6 11.2] Q0_s2 [4.3 4.3]\n",
      "greedy_policy1: s1 do a2; s2 indifferent.\n",
      "Iteration 2: V2: [14.098  7.177  0.   ] Q2_s1 [14.098 12.46 ] Q2_s2 [6.613 7.177]\n",
      "greedy_policy2: s1 do a1; s2 do a2.\n"
     ]
    }
   ],
   "source": [
    "gamma=1\n",
    "V0=np.array([10,1,0])\n",
    "Q1_s1=np.array([8,10])+gamma*np.array([[0.2,0.6,0.2],[0.1,0.2,0.7]])@V0\n",
    "Q1_s2=np.array([1,-1])+gamma*np.array([[0.3,0.3,0.4],[0.5,0.3,0.2]])@V0\n",
    "V1=np.array([Q1_s1.max(),Q1_s2.max(),0])\n",
    "print(\"Iteration 1:\",\"V1:\",V1,\"Q0_s1\",Q0_s1,\"Q0_s2\",Q0_s2)\n",
    "print(\"greedy_policy1: s1 do a2; s2 indifferent.\")\n",
    "\n",
    "Q1_s1=np.array([8,10])+gamma*np.array([[0.2,0.6,0.2],[0.1,0.2,0.7]])@V1\n",
    "Q1_s2=np.array([1,-1])+gamma*np.array([[0.3,0.3,0.4],[0.5,0.3,0.2]])@V1\n",
    "V2=np.array([Q2_s1.max(),Q2_s2.max(),0])\n",
    "print(\"Iteration 2:\",\"V2:\",V2,\"Q2_s1\",Q2_s1,\"Q2_s2\",Q2_s2)\n",
    "print(\"greedy_policy2: s1 do a1; s2 do a2.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest, I don't see an obvious reason why greedy_policy in iteration2 will just be the optimal policy. To me, it seems like the optimal policy is simply to stay away from terminating state s3 and it's a self-reinforcing process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will do it later since already covered in practice midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will do it later since already covered in practice midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't write out the entire code, but I guess you can see where I'm heading to. The brute force method I'm using doesn't look like efficient enough to me. Is there a better method, such as an interaction between two SimpleInventoryMDP Objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.markov_decision_process import FinitePolicy, StateActionMapping\n",
    "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
    "from rl.distribution import Categorical, Constant\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class InventoryState:\n",
    "    on_hand: int\n",
    "    on_order: int\n",
    "    def inventory_position(self) -> int:\n",
    "        return self.on_hand + self.on_order\n",
    "\n",
    "\n",
    "InvOrderMapping = StateActionMapping[InventoryState, int]\n",
    "\n",
    "\n",
    "class TwoInventoryMDPCap(FiniteMarkovDecisionProcess[InventoryState, int]):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity_1: int,\n",
    "        poisson_lambda_1: float,\n",
    "        holding_cost_1: float,\n",
    "        stockout_cost_1: float,\n",
    "        capacity_2: int,\n",
    "        poisson_lambda_2: float,\n",
    "        holding_cost_2: float,\n",
    "        stockout_cost_2: float,\n",
    "        K1: int,\n",
    "        K2: int\n",
    "    ):\n",
    "        self.capacity_1: int= capacity_1\n",
    "        self.poisson_lambda_1: float=poisson_lambda_1\n",
    "        self.holding_cost_1: float=holding_cost_1\n",
    "        self.stockout_cost_1: float=stockout_cost_1\n",
    "        self.capacity_2: int=capacity_2\n",
    "        self.poisson_lambda_2: float=poisson_lambda_2\n",
    "        self.holding_cost_2: float=holding_cost_2\n",
    "        self.stockout_cost_2: float=stockout_cost_2\n",
    "        self.K1: int=K1\n",
    "        self.K2: int=K2\n",
    "        self.poisson_distr_1 = poisson(poisson_lambda_1)\n",
    "        self.poisson_distr_2 = poisson(poisson_lambda_2)\n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> InvOrderMapping:\n",
    "        \"\"\"\n",
    "        state: two InventoryStates; action:(supplier_order_1,supplier_order_2,transport(from 1 to 2)),\n",
    "        reward:-(holding_cost_1+stock_out_cost_1+supplier_trans_1+holding_cost_2+stock_out_cost_2+supplier_trans_2+trans_cost)\n",
    "        \"\"\"\n",
    "        d: Dict[Tuple[InventoryState,InventoryState], Dict[Tuple[int,int,int], Categorical[Tuple[Tuple[InventoryState,InventoryState],\n",
    "                                                            float]]]] = {}\n",
    "        \n",
    "        for on_hand_1 in range(self.capacity_1 + 1):\n",
    "            for on_hand_2 in range(self.capacity_2 + 1):\n",
    "                for on_order_1 in range(self.capacity_1 + 1 - on_hand_1):\n",
    "                    for on_order_2 in range(self.capacity_2 + 1 - on_hand_2):\n",
    "                        k_max=min(on_hand_1,self.capacity_2-on_hand_2-on_order_2)\n",
    "                        k_min=-min(on_hand_2,self.capacity_1-on_hand_1-on_order_1)\n",
    "                        for trans in range(k_min,k_max):\n",
    "                            # Here the problem isn't clear enough. I assume the transportation between stores\n",
    "                            #happens immediately. This definition determines how we calculate overnight holding cost.\n",
    "                            state_1: InventoryState = InventoryState(on_hand_1-trans, on_order_1)\n",
    "                            state_2: InventoryState = InventoryState(on_hand_2+trans, on_order_2)\n",
    "                            ip_1: int = state_1.inventory_position()\n",
    "                            ip_2: int = state_2.inventory_position()\n",
    "                            base_reward_1: float = - self.holding_cost_1 * state_1.on_hand\n",
    "                            base_reward_2: float = - self.holding_cost_2 * state_2.on_hand\n",
    "                            d1: Dict[Tuple[int,int,int], Categorical[Tuple[Tuple[InventoryState,InventoryState], float]]] = {}\n",
    "                            # loop order1 and order2\n",
    "                            for order1 in range(self.capacity_1 - ip_1 + 1):\n",
    "                                for order2 in range(self.capacity_2 - ip_2 + 1):\n",
    "                                    sr_probs_dict: Dict[Tuple[Tuple[InventoryState,InventoryState], float]] =\\\n",
    "                                    {((InventoryState(ip_1 - i, order1),InventoryState(ip_2 - j, order2)), \\\n",
    "                                    base_reward):self.poisson_distr_1.pmf(i)*self.poisson_distr_2.pmf(j) \\\n",
    "                                      for i,j in zip(range(ip_1),range(ip_2))}\n",
    "\n",
    "                        d1[(order1,order2,trans)] = Categorical(sr_probs_dict)\n",
    "\n",
    "                        d[(InventoryState(on_hand_1, on_order_1),InventoryState(on_hand_2, on_order_2))] = d1\n",
    "        return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sr_probs_dict' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-2a30e3e0eec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m new_simulation=TwoInventoryMDPCap(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mcapacity_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mpoisson_lambda_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mholding_cost_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mstockout_cost_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-0b183bcbefa7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, capacity_1, poisson_lambda_1, holding_cost_1, stockout_cost_1, capacity_2, poisson_lambda_2, holding_cost_2, stockout_cost_2, K1, K2)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoisson_distr_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoisson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoisson_lambda_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoisson_distr_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoisson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoisson_lambda_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action_transition_reward_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action_transition_reward_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mInvOrderMapping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-0b183bcbefa7>\u001b[0m in \u001b[0;36mget_action_transition_reward_map\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m                                       for i,j in zip(range(ip_1),range(ip_2))}\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                         \u001b[0md1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_probs_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                         \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInventoryState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon_hand_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_order_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mInventoryState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon_hand_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_order_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'sr_probs_dict' referenced before assignment"
     ]
    }
   ],
   "source": [
    "new_simulation=TwoInventoryMDPCap(\n",
    "        capacity_1=2,\n",
    "        poisson_lambda_1=1,\n",
    "        holding_cost_1=1,\n",
    "        stockout_cost_1=10,\n",
    "        capacity_2=2,\n",
    "        poisson_lambda_2=2,\n",
    "        holding_cost_2=1,\n",
    "        stockout_cost_2=10,\n",
    "        K1=1,\n",
    "        K2=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
