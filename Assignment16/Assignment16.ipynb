{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "from typing import Iterable, Iterator, Tuple, TypeVar\n",
    "\n",
    "from rl.distribution import Distribution\n",
    "from rl.function_approx import FunctionApprox\n",
    "import rl.markov_process as mp\n",
    "import rl.markov_decision_process as markov_decision_process\n",
    "from rl.markov_decision_process import (MarkovDecisionProcess)\n",
    "from rl.returns import returns\n",
    "from rl.score_func import score_func\n",
    "S = TypeVar('S')\n",
    "A = TypeVar('A')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "### 1) How to calculate gradient of theta and gradient of value_function? Are they known functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD-actor_critic(\n",
    "        mdp: MarkovDecisionProcess[S, A],\n",
    "        states: Distribution[S],\n",
    "        alpha: float,\n",
    "        gamma: float,\n",
    "):\n",
    "    def get_actions_and_next_states(self, nt_state: S) \\\n",
    "            -> Set[Tuple[A, S]]:\n",
    "        '''\n",
    "        given a non-terminal state, returns the set of all possible\n",
    "        (action, next_state) pairs\n",
    "        '''\n",
    "        temp: Set[Tuple[A, S]] = {(a, mdp.TransitionStep(a,s)\n",
    "                                        for a in possible_moves}\n",
    "        return {(a, s) for a, s in temp}\n",
    "                                   \n",
    "    # initialize theta and G\n",
    "    S=mdp.states()\n",
    "    value_function={Si:0 for Si in S}\n",
    "    theta=value_function # randomly generate theta\n",
    "    while True:\n",
    "        trace: Iterable[markov_decision_process.TransitionStep[S, A]] =\\\n",
    "            mdp.simulate_actions(states, p)\n",
    "        trace=list(trace)\n",
    "        P=1\n",
    "        for step_t in enumerate(trace):\n",
    "            if not mdp.is_terminal(step_t[0]):\n",
    "                current_s: S=step_t[0]\n",
    "                a: A=get_actions_and_next_states(current_s)\n",
    "                error: float=step_t[2]+gamma*value_function[step_t[0]]-value_function[step_t[0]]\n",
    "                value_function[step_t[0]]=value_function[step_t[0]]+alpha*error*gradient(value_function[step_t[0]])\n",
    "                theta[step_t[0]]=theta[step_t[0]]+alpha*error*gradient(theta[step_t[0]])\n",
    "                p=gamma*P\n",
    "                current_s=step_t[1]\n",
    "    return theta,value_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_pg(\n",
    "        mdp: MarkovDecisionProcess[S, A],\n",
    "        states: Distribution[S],\n",
    "        alpha: float,\n",
    "        gamma: float,\n",
    "):\n",
    "    # initialize theta and G\n",
    "    S=mdp.states()\n",
    "    G=np.zeros(len(S))\n",
    "    theta=np.random.randn(len(G))\n",
    "    while True:\n",
    "        trace: Iterable[markov_decision_process.TransitionStep[S, A]] =\\\n",
    "            mdp.simulate_actions(states, p)\n",
    "        trace=list(trace)\n",
    "        for t,step_t in enumerate(trace):\n",
    "            t_left=T-t\n",
    "            gammas=np.cumprod(gamma,t_left)/gamma\n",
    "            G=np.dot(gammas,step_t[2])\n",
    "            theta=theta+gammas[-1]*gamma*alpha*np.dot(score_func(step_t[0],step_t[1],theta),G)\n",
    "        yield theta\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
